---
title: "Class8: Breast Cancer Mini Project"
author: "Sawyer (PID: A16335277)"
format: pdf
---

Before we get stuck into project work we will have a quick look at applying PCA to some example RNASeq data (tail en of lab 7).

Read the data (detailed in lab 7):

```{r}
url2 <- "https://tinyurl.com/expression-CSV"
rna.data <- read.csv(url2, row.names=1)
head(rna.data)
```

> Q. How many genes are in this dataset?

```{r}
nrow(rna.data)
```

## Run PCA

```{r}
## Again we have to take the transpose of our data 
pca <- prcomp(t(rna.data), scale=TRUE)
 
## Simple un polished plot of pc1 and pc2
plot(pca$x[,1], pca$x[,2], xlab="PC1", ylab="PC2")
```

```{r}
summary(pca)
```

```{r}
# We have 5 wt and 5 ko samples
mycols <- c(rep("blue", 5), rep("red", 5))

plot(pca$x[,1], pca$x[,2], xlab="PC1", ylab="PC2", col=mycols)
```


I could examine which genes contribute most to this first PC

```{r}
head(sort(abs(pca$rotation[,1]), decreasing = T))
```

# 1. Analysis of Breast Cancer FNA data.

```{r}
# Save your input data file into your Project directory
fna.data <- "WisconsinCancer.csv"

# Complete the following code to input the data and store as wisc.df
wisc.df <- read.csv(fna.data, row.names=1)
head(wisc.df)
```

```{r}
# Create diagnosis vector for later 
diagnosis <- as.factor(wisc.df$diagnosis)

# We can use -1 here to remove the first column
wisc.data <- wisc.df[,-1]
```

- Q1. How many observations are in this dataset?

```{r}
nrow(wisc.data)
```

- Q2. How many of the observations have a malignant diagnosis?

```{r}
table(diagnosis)
```

- Q3. How many variables/features in the data are suffixed with _mean?

```{r}
# alternate method
sum(endsWith(names(wisc.data), '_mean'))
```

```{r}
length(grep('_mean', names(wisc.data)))
```


## 2. PCA

Here we will use `prcomp()` on the `wisc.data` object - the one without the diagnosis column.

First, we have to decide whether to use the `scale=TRUE` argument when we run `prcomp()`.

we can look at the means and sd of each column. If they are similar then we are all good to go. If not we should use `scale=TRUE`

```{r}
colMeans(wisc.data)
```
```{r}
apply(wisc.data, 2, sd)
```

These are very different so we should set `scale=True`.

```{r}
wisc.pr <- prcomp(wisc.data, scale=TRUE)
summary(wisc.pr)
```



> Q4. From your results, what proportion of the original variance is captured by the first principal components (PC1)?

0.4427 or 44.27%

> Q5. How many principal components (PCs) are required to describe at least 70% of the original variance in the data?

3 PCs capture 72.6% of the original variance.

> Q6. How many principal components (PCs) are required to describe at least 90% of the original variance in the data?

7 PCs capture 91% of the original variance.

### Plotting the PCA results

```{r}
biplot(wisc.pr)
```


> Q7. What stands out to you about this plot? Is it easy or difficult to understand? Why?

This plot is so cluttered and the individual data points are impossible to discern. ("Hot mess")

We need to make our own plot.

```{r}
attributes(wisc.pr)
```
```{r}
plot(wisc.pr$x[,1], wisc.pr$x[,2], col=diagnosis)
```
```{r}
library(ggplot2)

pc <- as.data.frame(wisc.pr$x)

ggplot(pc) +
  aes(PC1, PC2, col=diagnosis) +
  geom_point()
```


> Q9. For the first principal component, what is the component of the loading vector (i.e. wisc.pr$rotation[,1]) for the feature concave.points_mean?

```{r}
wisc.pr$rotation["concave.points_mean",1]
```

> Q10. What is the minimum number of principal components required to explain 80% of the variance of the data?

```{r}
tbl <- summary(wisc.pr)
which(tbl$importance[3,] > 0.8)[1]
```

## 3. Hierarchical clustering

The main function for Hierarchical clustering is called `hclust()` it takes a distance matrix as input.

```{r}
d <- dist(scale(wisc.data))
wisc.hclust <- hclust(d)
plot(wisc.hclust)
abline(h=18, col="red")
grps <- cutree(wisc.hclust, h=18)
table(grps)
```


Come back here later to see how our cluster grps correspond to M or B groups.

```{r}
pc <- as.data.frame(wisc.pr$x)

ggplot(pc) +
  aes(PC1, PC2, col=diagnosis) +
  geom_point()
```

## 5. Combining Methods

Here we will perform clustering on PCA results rather than the original data.

In other words we will cluster using `wisc.pr$x` - our new better variables or PCs. We can chose as many or as few PCs to use as we like. It is your call!

```{r}
d.pc <- dist(wisc.pr$x[,1:3])
wisc.pr.hclust <- hclust(d.pc, method="ward.D2")
plot(wisc.pr.hclust)
abline(h=80, col="red")
```

```{r}
grps <- cutree(wisc.pr.hclust, h=80)
table(grps)
```

We can use `table()` function to make a cross-table as well as just a count table.

```{r}
table(diagnosis)
```
```{r}
table(grps, diagnosis)
```

Write a note here about how to read this cross-table result:

This table shows the occurrence of both classes in the diagnosis vector and the clusters we've defined. We can see that cluster 1 corresponds to a Malignant diagnosis and cluster 2 corresponds to a Benign diagnosis. There are some false positives/negatives, but the overall result is pretty good.

## 7. Prediction

```{r}
#url <- "new_samples.csv"
url <- "https://tinyurl.com/new-samples-CSV"
new <- read.csv(url)
npc <- predict(wisc.pr, newdata=new)
npc
```

And plot this up
```{r}
plot(wisc.pr$x[,1:2], col=grps)
points(npc[,1], npc[,2], col="blue", pch=16, cex=3)
text(npc[,1], npc[,2], c(1,2), col="white")
```

> Q18. Which of these new patients should we prioritize for follow up based on your results?

We should prioritize group 2 (malignant) patients because their condition is likely more concerning.
